"""
æ ¡å›­å¤±ç‰©æ‹›é¢†AIåŒ¹é…å¹³å° - BERTæ·±åº¦å­¦ä¹ æ¨¡å‹ + é€šä¹‰åƒé—®API
"""

from flask import Flask, request, jsonify, render_template, send_from_directory
from flask_cors import CORS
import json
import os
import datetime
import uuid
from pathlib import Path
from werkzeug.utils import secure_filename
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel
import traceback
from dateutil import parser  # ã€æ–°å¢ã€‘ç”¨äºè§£ææ—¶é—´

# å¯¼å…¥é€šä¹‰åƒé—®è¾…åŠ©æ¨¡å—
from qianwen_helper import qianwen

app = Flask(__name__, static_folder='static', template_folder='templates')
CORS(app)

# é…ç½®
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}
UPLOAD_FOLDER = 'uploads'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024

# ç¡®ä¿ç›®å½•å­˜åœ¨
for dir_name in [UPLOAD_FOLDER, 'data', 'exports']:
    Path(dir_name).mkdir(exist_ok=True)

# æ¨¡æ‹Ÿæ•°æ®åº“
lost_items = []
found_items = []
matches = []


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


# ==================== BERTæ·±åº¦å­¦ä¹ æ¨¡å‹ç±» ====================
class BertMatcher:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"BERTæ¨¡å‹ - ä½¿ç”¨è®¾å¤‡: {self.device}")
        self.model = None
        self.tokenizer = None
        self.model_loaded = False
        self.init_model()

    def init_model(self):
        try:
            print("æ­£åœ¨åŠ è½½BERTæ·±åº¦å­¦ä¹ æ¨¡å‹...")
            model_path = r"C:\Users\ASUS\Desktop\pythonwork\campus_lost_and_found\model"

            if os.path.exists(model_path):
                try:
                    print("åŠ è½½æœ¬åœ°BERTæ¨¡å‹...")
                    self.tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
                    self.model = AutoModel.from_pretrained(model_path, local_files_only=True)
                    self.model = self.model.to(self.device)
                    self.model.eval()

                    # æµ‹è¯•æ¨¡å‹
                    test_text = "æµ‹è¯•æ–‡æœ¬"
                    inputs = self.tokenizer(test_text, return_tensors="pt", truncation=True, max_length=10)
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                    with torch.no_grad():
                        outputs = self.model(**inputs)

                    if outputs.last_hidden_state is not None:
                        print("BERTæ¨¡å‹åŠ è½½æˆåŠŸ")
                        self.model_loaded = True
                    else:
                        self.load_online_model()

                except Exception as e:
                    print(f"æœ¬åœ°BERTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                    self.load_online_model()
            else:
                self.load_online_model()

        except Exception as e:
            print(f"BERTæ¨¡å‹åˆå§‹åŒ–é”™è¯¯: {e}")
            self.model_loaded = False

    def load_online_model(self):
        try:
            model_name = "bert-base-chinese"
            print(f"ä¸‹è½½åœ¨çº¿æ¨¡å‹: {model_name}")
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModel.from_pretrained(model_name)
            self.model = self.model.to(self.device)
            self.model.eval()
            self.model_loaded = True
            print("åœ¨çº¿BERTæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"åœ¨çº¿æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model_loaded = False

    def calculate_similarity(self, text1: str, text2: str) -> float:
        if not self.model_loaded:
            print("âš ï¸ BERTæ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨ç®€å•ç›¸ä¼¼åº¦")
            return float(self.simple_similarity(text1, text2))

        try:
            # æå–ç‰¹å¾
            inputs1 = self.tokenizer(text1, return_tensors="pt", truncation=True, max_length=128)
            inputs2 = self.tokenizer(text2, return_tensors="pt", truncation=True, max_length=128)
            inputs1 = {k: v.to(self.device) for k, v in inputs1.items()}
            inputs2 = {k: v.to(self.device) for k, v in inputs2.items()}

            with torch.no_grad():
                outputs1 = self.model(**inputs1)
                outputs2 = self.model(**inputs2)

            # ä½¿ç”¨[CLS] tokençš„ç‰¹å¾
            feat1 = outputs1.last_hidden_state[:, 0, :].cpu().numpy().flatten()
            feat2 = outputs2.last_hidden_state[:, 0, :].cpu().numpy().flatten()

            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            norm1 = np.linalg.norm(feat1)
            norm2 = np.linalg.norm(feat2)
            if norm1 == 0 or norm2 == 0:
                return 0.0

            raw_similarity = np.dot(feat1, feat2) / (norm1 * norm2)

            # å…³é”®ä¿®å¤ï¼šå°†numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿfloat
            raw_similarity = float(raw_similarity)

            print(f"ğŸ“Š BERTåŸå§‹ç›¸ä¼¼åº¦: {raw_similarity:.4f} (æ–‡æœ¬1: '{text1[:30]}...' æ–‡æœ¬2: '{text2[:30]}...')")

            # ========== ä¿®å¤ï¼šæ›´ä¸¥æ ¼çš„è¯„åˆ†æ˜ å°„ ==========
            # BERTå¯¹ä¸­æ–‡çŸ­æ–‡æœ¬ç›¸ä¼¼åº¦é€šå¸¸åé«˜ï¼Œéœ€è¦ä¿å®ˆæ˜ å°„

            if raw_similarity < 0.4:
                # 0.0-0.4: å®Œå…¨ä¸ç›¸å…³ -> 0-20åˆ†
                adjusted = raw_similarity / 0.4 * 0.2
            elif raw_similarity < 0.65:
                # 0.4-0.65: å¯èƒ½ç›¸å…³ -> 20-50åˆ†
                adjusted = 0.2 + (raw_similarity - 0.4) / (0.65 - 0.4) * 0.3
            elif raw_similarity < 0.8:
                # 0.65-0.8: ç›¸å…³ -> 50-75åˆ†
                adjusted = 0.5 + (raw_similarity - 0.65) / (0.8 - 0.65) * 0.25
            elif raw_similarity < 0.9:
                # 0.8-0.9: é«˜åº¦ç›¸å…³ -> 75-90åˆ†
                adjusted = 0.75 + (raw_similarity - 0.8) / (0.9 - 0.8) * 0.15
            elif raw_similarity < 0.95:
                # 0.9-0.95: éå¸¸ç›¸å…³ -> 90-95åˆ†
                adjusted = 0.9 + (raw_similarity - 0.9) / (0.95 - 0.9) * 0.05
            else:
                # >0.95: å‡ ä¹ç›¸åŒ -> 95-100åˆ†
                adjusted = 0.95 + (raw_similarity - 0.95) / (1.0 - 0.95) * 0.05

            # ç¡®ä¿åˆ†æ•°åœ¨0-1ä¹‹é—´
            adjusted = max(0.0, min(1.0, adjusted))
            print(f"ğŸ¯ BERTè°ƒæ•´åç›¸ä¼¼åº¦: {adjusted:.4f}")
            return float(adjusted)

        except Exception as e:
            print(f"BERTç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {e}")
            return float(self.simple_similarity(text1, text2))

    def simple_similarity(self, text1: str, text2: str) -> float:
        if not text1 or not text2:
            return 0.0
        try:
            words1 = set(str(text1).lower().split())
            words2 = set(str(text2).lower().split())
            if not words1 or not words2:
                return 0.0
            intersection = len(words1.intersection(words2))
            union = len(words1.union(words2))
            return float(intersection / union if union > 0 else 0.0)
        except:
            return 0.0


# ==================== AIæ™ºèƒ½åŒ¹é…å¼•æ“ ====================
class AIMatcher:
    def __init__(self):
        self.bert_matcher = BertMatcher()
        print("AIæ™ºèƒ½åŒ¹é…å¼•æ“åˆå§‹åŒ–å®Œæˆ")

    # ã€æ–°å¢ã€‘æ£€æŸ¥æ—¶é—´æ˜¯å¦å†²çª
    def is_time_conflict(self, lost_date_str, found_date_str):
        if not lost_date_str or not found_date_str:
            return False
        try:
            # å°è¯•è§£ææ—¶é—´å­—ç¬¦ä¸²
            t1 = parser.parse(str(lost_date_str))
            t2 = parser.parse(str(found_date_str))
            
            # å¦‚æœ æ‹¾è·æ—¶é—´(t2) < ä¸¢å¤±æ—¶é—´(t1)ï¼Œåˆ™æ˜¯å†²çª
            # æ¯”å¦‚ï¼š10å·ä¸¢çš„ï¼Œä¸å¯èƒ½9å·å°±æ¡åˆ°äº†
            if t2 < t1:
                return True
            return False
        except Exception as e:
            print(f"æ—¶é—´è§£æé”™è¯¯: {e} (å¯èƒ½æ˜¯æ ¼å¼ä¸æ”¯æŒï¼Œè·³è¿‡æ—¶é—´æ£€æŸ¥)")
            return False

    def match_items(self, lost_item: dict, found_item: dict) -> dict:
        try:
            # ã€æ–°å¢ã€‘1. ä¼˜å…ˆè¿›è¡Œæ—¶é—´é€»è¾‘æ£€æŸ¥ï¼ˆç¡¬çº¦æŸï¼‰
            lost_date = lost_item.get('lost_date')
            found_date = found_item.get('found_date')
            
            if self.is_time_conflict(lost_date, found_date):
                print(f"âš ï¸ æ—¶é—´é€»è¾‘å†²çª: ä¸¢å¤±({lost_date}) > æ‹¾è·({found_date})")
                return {
                    'match_score': 0.0,
                    'bert_score': 0.0,
                    'qianwen_analysis': f"æ—¶é—´é€»è¾‘å†²çªï¼šæ‹¾è·æ—¶é—´({found_date}) æ—©äº ä¸¢å¤±æ—¶é—´({lost_date})ï¼Œè¿™åœ¨é€»è¾‘ä¸Šæ˜¯ä¸å¯èƒ½çš„ã€‚",
                    'match_level': "ä¸åŒ¹é…"
                }

            # è°ƒè¯•ä¿¡æ¯
            print(f"\nğŸ” åŒ¹é…è¯¦æƒ…:")
            print(f"  ä¸¢å¤±ç‰©å“æ ‡é¢˜: '{lost_item.get('title')}'")
            print(f"  ä¸¢å¤±ç‰©å“æè¿°: '{lost_item.get('description')}'")
            print(f"  ä¸¢å¤±ç‰©å“ç±»åˆ«: '{lost_item.get('category')}'")
            print(f"  æ‹›é¢†ç‰©å“æ ‡é¢˜: '{found_item.get('title')}'")
            print(f"  æ‹›é¢†ç‰©å“æè¿°: '{found_item.get('description')}'")
            print(f"  æ‹›é¢†ç‰©å“ç±»åˆ«: '{found_item.get('category')}'")

            # ========== æ–¹æ¡ˆ2ï¼šåˆ†åˆ«è®¡ç®—ä¸åŒéƒ¨åˆ†çš„ç›¸ä¼¼åº¦ ==========
            print(f"\nğŸ“Š å¼€å§‹åˆ†é¡¹è®¡ç®—ç›¸ä¼¼åº¦:")

            # 1. æ ‡é¢˜ç›¸ä¼¼åº¦ï¼ˆæƒé‡25%ï¼‰
            title_sim = self.bert_matcher.calculate_similarity(
                lost_item.get('title', ''),
                found_item.get('title', '')
            )

            # 2. æè¿°ç›¸ä¼¼åº¦ï¼ˆæƒé‡50%ï¼‰
            desc_sim = self.bert_matcher.calculate_similarity(
                lost_item.get('description', ''),
                found_item.get('description', '')
            )

            # 3. ç±»åˆ«ç›¸ä¼¼åº¦ï¼ˆæƒé‡25%ï¼‰
            category_sim = self.bert_matcher.calculate_similarity(
                lost_item.get('category', ''),
                found_item.get('category', '')
            )

            # åŠ æƒç»¼åˆ
            bert_score = (title_sim * 0.1 + desc_sim * 0.8 + category_sim * 0.1) * 100

            print(f"\nğŸ¯ åˆ†é¡¹ç›¸ä¼¼åº¦ç»“æœ:")
            print(f"  æ ‡é¢˜ç›¸ä¼¼åº¦: {title_sim:.4f} (æƒé‡10%) -> {title_sim*100:.1f}åˆ†")
            print(f"  æè¿°ç›¸ä¼¼åº¦: {desc_sim:.4f} (æƒé‡80%) -> {desc_sim*100:.1f}åˆ†")
            print(f"  ç±»åˆ«ç›¸ä¼¼åº¦: {category_sim:.4f} (æƒé‡10%) -> {category_sim*100:.1f}åˆ†")
            print(f"  åŠ æƒç»¼åˆBERTåˆ†æ•°: {bert_score:.1f}/100")

            # é€šä¹‰åƒé—®åˆ†æ
            qianwen_analysis = self.get_qianwen_analysis(lost_item, found_item, bert_score)
            print(f"  é€šä¹‰åƒé—®åˆ†ææ‘˜è¦: {qianwen_analysis[:50]}...")

            # æ ¹æ®é€šä¹‰åƒé—®åˆ†æè°ƒæ•´åˆ†æ•°
            final_score = self.adjust_score_by_qianwen(bert_score, qianwen_analysis, lost_item, found_item)

            print(f"  æœ€ç»ˆåŒ¹é…åˆ†æ•°: {final_score:.1f}/100")

            return {
                'match_score': round(final_score, 1),
                'bert_score': round(bert_score, 1),
                'qianwen_analysis': qianwen_analysis,
                'match_level': self.get_match_level(final_score)
            }

        except Exception as e:
            print(f"åŒ¹é…é”™è¯¯: {e}")
            return {
                'match_score': 0.0,
                'bert_score': 0.0,
                'qianwen_analysis': f"åŒ¹é…å¤±è´¥: {str(e)}",
                'match_level': "é”™è¯¯"
            }

    def adjust_score_by_qianwen(self, bert_score: float, analysis: str, lost_item: dict, found_item: dict) -> float:
        """æ ¹æ®é€šä¹‰åƒé—®çš„åˆ†æè°ƒæ•´åˆ†æ•°"""
        original_score = bert_score
        adjusted_score = bert_score

        # 1. æ£€æŸ¥åˆ†æä¸­çš„å¦å®šè¯ï¼ˆå¼ºçƒˆå¦å®šï¼‰
        strong_negative_keywords = [
            'ä¸å¯èƒ½', 'ä¸å¯èƒ½æ˜¯', 'è‚¯å®šä¸æ˜¯', 'ç»å¯¹ä¸æ˜¯', 'å®Œå…¨ä¸åŒ',
            'æ¯«æ— å…³ç³»', 'æ²¡æœ‰å…³è”', 'ä¸æ˜¯åŒä¸€ä¸ª'
        ]

        for keyword in strong_negative_keywords:
            if keyword in analysis:
                print(f"  âš ï¸ æ£€æµ‹åˆ°å¼ºçƒˆå¦å®šè¯: '{keyword}'ï¼Œå¤§å¹…é™ä½åˆ†æ•°")
                reduction = 0.7 if bert_score > 60 else 0.5
                adjusted_score = bert_score * (1 - reduction)
                break

        # 2. æ£€æŸ¥åˆ†æä¸­çš„æ¸©å’Œå¦å®šè¯
        if adjusted_score == bert_score:  # å¦‚æœè¿˜æ²¡è¢«è°ƒæ•´
            mild_negative_keywords = [
                'ä¸å¤ªå¯èƒ½', 'å¯èƒ½æ€§å°', 'éœ€è¦ç¡®è®¤', 'éœ€è¦æ ¸å®', 'å¯èƒ½ä¸åŒ',
                'å­˜åœ¨å·®å¼‚', 'ä¸ä¸€è‡´', 'æœ‰ç–‘é—®'
            ]

            for keyword in mild_negative_keywords:
                if keyword in analysis:
                    print(f"  âš ï¸ æ£€æµ‹åˆ°æ¸©å’Œå¦å®šè¯: '{keyword}'ï¼Œé€‚å½“é™ä½åˆ†æ•°")
                    reduction = 0.3 if bert_score > 70 else 0.2
                    adjusted_score = bert_score * (1 - reduction)
                    break

        # 3. æ£€æŸ¥åˆ†æä¸­çš„è‚¯å®šè¯
        if adjusted_score == bert_score:  # å¦‚æœè¿˜æ²¡è¢«è°ƒæ•´
            positive_keywords = [
                'å¯èƒ½åŒ¹é…', 'å¾ˆå¯èƒ½', 'é«˜åº¦ç›¸ä¼¼', 'éå¸¸ç›¸ä¼¼', 'å»ºè®®è”ç³»',
                'å¯èƒ½æ˜¯', 'åŒ¹é…åº¦é«˜', 'ç›¸ä¼¼åº¦é«˜'
            ]

            for keyword in positive_keywords:
                if keyword in analysis:
                    print(f"  âœ… æ£€æµ‹åˆ°è‚¯å®šè¯: '{keyword}'ï¼Œé€‚å½“æé«˜åˆ†æ•°")
                    boost = 0.1 if bert_score < 80 else 0.05
                    adjusted_score = bert_score * (1 + boost)
                    # é™åˆ¶æœ€é«˜åˆ†ï¼Œé˜²æ­¢è¶…è¿‡100
                    adjusted_score = min(95.0, adjusted_score)  # æœ€é«˜95åˆ†
                    break

        # 4. ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœBERTåˆ†æ•°å¾ˆé«˜ä½†ç‰©å“æ˜æ˜¾ä¸åŒï¼Œå¼ºåˆ¶é™ä½
        if bert_score > 70 and self.is_obviously_mismatch(lost_item, found_item):
            print(f"  âš ï¸ BERTé«˜åˆ†ä½†ç‰©å“æ˜æ˜¾ä¸åŒï¼Œå¼ºåˆ¶é™ä½åˆ†æ•°")
            adjusted_score = min(adjusted_score, 30.0)  # æœ€é«˜30åˆ†

        # 5. é˜²æ­¢åˆ†æ•°è¶…è¿‡100æˆ–ä½äº0
        adjusted_score = max(0.0, min(100.0, adjusted_score))

        # 6. å¯¹äºè¶…è¿‡95åˆ†çš„æƒ…å†µï¼Œç‰¹åˆ«å¤„ç†
        if adjusted_score > 95:
            print(f"  âš ï¸ åˆ†æ•°è¿‡é«˜({adjusted_score:.1f})ï¼Œè¿›è¡Œæœ€ç»ˆè°ƒæ•´")
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¦å®šè¯ï¼Œå³ä½¿ä¹‹å‰æ²¡åŒ¹é…åˆ°
            if any(keyword in analysis for keyword in ['ä¸åŒ', 'å·®å¼‚', 'ä¸ä¸€è‡´']):
                adjusted_score = max(adjusted_score * 0.8, 85.0)  # é™ä½ä½†ä¿æŒè¾ƒé«˜åˆ†

        if abs(adjusted_score - original_score) > 1.0:
            print(f"  åˆ†æ•°è°ƒæ•´: {original_score:.1f} â†’ {adjusted_score:.1f}")

        return float(adjusted_score)

    def is_obviously_mismatch(self, lost_item: dict, found_item: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜æ˜¾ä¸åŒ¹é…"""
        lost_title = lost_item.get('title', '').lower()
        found_title = found_item.get('title', '').lower()

        # å®šä¹‰æ˜æ˜¾ä¸åŒçš„ç‰©å“ç±»å‹
        mismatched_pairs = [
            ('é’¥åŒ™', 'æ ¡å›­å¡'), ('é’¥åŒ™', 'å­¦ç”Ÿå¡'), ('é’¥åŒ™', 'ä¸€å¡é€š'),
            ('æ‰‹æœº', 'ä¹¦åŒ…'), ('æ‰‹æœº', 'ä¹¦æœ¬'), ('æ‰‹æœº', 'æ°´æ¯'),
            ('é’±åŒ…', 'çœ¼é•œ'), ('é’±åŒ…', 'å……ç”µå™¨'), ('é’±åŒ…', 'è¡£æœ'),
            ('ä¹¦æœ¬', 'å……ç”µå®'), ('ä¹¦æœ¬', 'è€³æœº'), ('ä¹¦æœ¬', 'é›¨ä¼')
        ]

        for lost_type, found_type in mismatched_pairs:
            if (lost_type in lost_title and found_type in found_title) or \
               (found_type in lost_title and lost_type in found_title):
                return True

        return False

    def get_qianwen_analysis(self, lost_item: dict, found_item: dict, bert_score: float) -> str:
        try:
            prompt = f"""
            è¯·å®¢è§‚åˆ†æè¿™ä¸¤ä¸ªç‰©å“æ˜¯å¦å¯èƒ½åŒ¹é…ï¼š

            å½“å‰BERTç›¸ä¼¼åº¦è¯„åˆ†ï¼š{bert_score:.1f}/100

            ä¸¢å¤±ç‰©å“ä¿¡æ¯ï¼š
            - åç§°ï¼š{lost_item.get('title', 'æ— ')}
            - æè¿°ï¼š{lost_item.get('description', 'æ— ')}
            - ç±»åˆ«ï¼š{lost_item.get('category', 'æ— ')}
            - é¢œè‰²ï¼š{lost_item.get('color', 'æ— ')}
            - å“ç‰Œï¼š{lost_item.get('brand', 'æ— ')}
            - ä¸¢å¤±åœ°ç‚¹ï¼š{lost_item.get('lost_location', 'æ— ')}
            - ä¸¢å¤±æ—¶é—´ï¼š{lost_item.get('lost_date', 'æ— ')}

            æ‹›é¢†ç‰©å“ä¿¡æ¯ï¼š
            - åç§°ï¼š{found_item.get('title', 'æ— ')}
            - æè¿°ï¼š{found_item.get('description', 'æ— ')}
            - ç±»åˆ«ï¼š{found_item.get('category', 'æ— ')}
            - é¢œè‰²ï¼š{found_item.get('color', 'æ— ')}
            - å“ç‰Œï¼š{found_item.get('brand', 'æ— ')}
            - æ‹¾è·åœ°ç‚¹ï¼š{found_item.get('found_location', 'æ— ')}
            - æ‹¾è·æ—¶é—´ï¼š{found_item.get('found_date', 'æ— ')}

            è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢åˆ†æï¼š
            1. ç‰©å“åç§°ã€ç±»åˆ«ã€æè¿°æ˜¯å¦ä¸€è‡´æˆ–ç›¸ä¼¼
            2. å…³é”®ç‰¹å¾ï¼ˆé¢œè‰²ã€å“ç‰Œç­‰ï¼‰æ˜¯å¦åŒ¹é…
            3. ä¸¢å¤±å’Œæ‹¾è·çš„åœ°ç‚¹ã€æ—¶é—´æ˜¯å¦æœ‰ç›¸å…³æ€§
            4. ç»™å‡ºæœ€ç»ˆåˆ¤æ–­ï¼šæ˜¯å¦å¯èƒ½æ˜¯åŒä¸€ä¸ªç‰©å“

            è¯·ç”¨ç®€æ´å®¢è§‚çš„è¯­è¨€åˆ†æï¼Œä¸è¦é‡å¤BERTåˆ†æ•°ã€‚
            """

            response = qianwen.chat(prompt, [])
            return response.strip()[:300]

        except Exception as e:
            print(f"é€šä¹‰åƒé—®åˆ†æå¤±è´¥: {e}")
            return "AIåˆ†ææš‚ä¸å¯ç”¨"

    def get_match_level(self, score: float) -> str:
        # è°ƒæ•´åŒ¹é…ç­‰çº§é˜ˆå€¼
        if score >= 75:
            return "é«˜åº¦åŒ¹é…"
        elif score >= 55:
            return "ä¸­åº¦åŒ¹é…"
        elif score >= 35:
            return "è½»åº¦åŒ¹é…"
        elif score >= 15:
            return "å¯èƒ½ç›¸å…³"
        else:
            return "ä¸åŒ¹é…"


# åˆå§‹åŒ–AIåŒ¹é…å¼•æ“
print("å¯åŠ¨æ ¡å›­å¤±ç‰©æ‹›é¢†AIåŒ¹é…å¹³å°")
ai_matcher = AIMatcher()


# ==================== è·¯ç”±å®šä¹‰ ====================
@app.route('/')
def index():
    return render_template('index.html')


@app.route('/lost')
def show_lost():
    return render_template('lost_items.html', items=lost_items)


@app.route('/found')
def show_found():
    return render_template('found_items.html', items=found_items)


@app.route('/match')
def show_match():
    return render_template('match.html')


@app.route('/ai/assistant')
def ai_assistant():
    return render_template('ai_assistant.html')


@app.route('/submit/lost')
def submit_lost_page():
    return render_template('submit_lost.html')


@app.route('/submit/found')
def submit_found_page():
    return render_template('submit_found.html')


@app.route('/api/submit/lost', methods=['POST'])
def submit_lost():
    try:
        data = request.json
        item_data = {
            'id': str(uuid.uuid4())[:8],
            'title': data.get('title', ''),
            'description': data.get('description', ''),
            'category': data.get('category', ''),
            'color': data.get('color', ''),
            'brand': data.get('brand', ''),
            'lost_date': data.get('lost_date', ''),
            'lost_location': data.get('lost_location', ''),
            'contact_name': data.get('contact_name', ''),
            'contact_phone': data.get('contact_phone', ''),
            'contact_email': data.get('contact_email', ''),
            'image_url': data.get('image_url', ''),
            'status': 'å¯»æ‰¾ä¸­',
            'created_at': datetime.datetime.now().isoformat()
        }
        lost_items.append(item_data)
        return jsonify({'success': True, 'item_id': item_data['id'], 'message': 'ä¸¢å¤±ç‰©å“å·²æäº¤'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/submit/found', methods=['POST'])
def submit_found():
    try:
        data = request.json
        item_data = {
            'id': str(uuid.uuid4())[:8],
            'title': data.get('title', ''),
            'description': data.get('description', ''),
            'category': data.get('category', ''),
            'color': data.get('color', ''),
            'brand': data.get('brand', ''),
            'found_date': data.get('found_date', ''),
            'found_location': data.get('found_location', ''),
            'contact_name': data.get('contact_name', ''),
            'contact_phone': data.get('contact_phone', ''),
            'contact_email': data.get('contact_email', ''),
            'image_url': data.get('image_url', ''),
            'status': 'å¾…è®¤é¢†',
            'created_at': datetime.datetime.now().isoformat()
        }
        found_items.append(item_data)
        return jsonify({'success': True, 'item_id': item_data['id'], 'message': 'æ‹›é¢†ç‰©å“å·²æäº¤'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/items/lost', methods=['GET'])
def get_lost_items():
    return jsonify({'items': lost_items, 'count': len(lost_items)})


@app.route('/api/items/found', methods=['GET'])
def get_found_items():
    return jsonify({'items': found_items, 'count': len(found_items)})


@app.route('/api/item/<item_id>', methods=['GET'])
def get_item(item_id):
    for item in lost_items:
        if item['id'] == item_id:
            return jsonify({'item': item, 'type': 'lost'})
    for item in found_items:
        if item['id'] == item_id:
            return jsonify({'item': item, 'type': 'found'})
    return jsonify({'error': 'ç‰©å“ä¸å­˜åœ¨'}), 404

@app.route('/lost/<item_id>')
def lost_item_detail(item_id):
    for item in lost_items:
        if item['id'] == item_id:
            return render_template('lost_item_detail.html', item=item)
    return "ç‰©å“ä¸å­˜åœ¨", 404

@app.route('/found/<item_id>')
def found_item_detail(item_id):
    for item in found_items:
        if item['id'] == item_id:
            return render_template('found_item_detail.html', item=item)
    return "ç‰©å“ä¸å­˜åœ¨", 404

@app.route('/api/match', methods=['POST'])
def match_items():
    """
    å…¼å®¹æ€§åŒ¹é…API - è½¬å‘åˆ°æ·±åº¦åŒ¹é…
    æ”¯æŒä¸¤ç§å‚æ•°æ ¼å¼:
    1. {lost_item_id, found_item_id} - ç²¾ç¡®åŒ¹é…ä¸¤ä¸ªç‰©å“
    2. {found_item_id} - æœç´¢åŒ¹é…çš„ä¸¢å¤±ç‰©å“
    3. {lost_item_id} - æœç´¢åŒ¹é…çš„æ‹›é¢†ç‰©å“
    """
    try:
        data = request.json
        lost_item_id = data.get('lost_item_id')
        found_item_id = data.get('found_item_id')

        print(f"\nğŸ“ æ”¶åˆ°åŒ¹é…è¯·æ±‚ (å…¼å®¹æ¨¡å¼):")
        print(f"   å‚æ•°: {data}")

        # æ¨¡å¼1: ç²¾ç¡®åŒ¹é…ä¸¤ä¸ªç‰©å“
        if lost_item_id and found_item_id:
            print("   æ¨¡å¼: ç²¾ç¡®åŒ¹é…ä¸¤ä¸ªç‰©å“")

            # æŸ¥æ‰¾ç‰©å“
            lost_item = None
            found_item = None

            for item in lost_items:
                if item['id'] == lost_item_id:
                    lost_item = item
                    break

            for item in found_items:
                if item['id'] == found_item_id:
                    found_item = item
                    break

            if not lost_item or not found_item:
                return jsonify({'error': 'ç‰©å“ä¸å­˜åœ¨'}), 404

            # è¿›è¡ŒåŒ¹é…
            match_result = ai_matcher.match_items(lost_item, found_item)

            # ä¿å­˜åŒ¹é…è®°å½•
            match_record = {
                'id': str(uuid.uuid4())[:8],
                'lost_item_id': lost_item_id,
                'found_item_id': found_item_id,
                'match_result': match_result,
                'timestamp': datetime.datetime.now().isoformat()
            }
            matches.append(match_record)

            return jsonify({
                'success': True,
                'match_id': match_record['id'],
                'match_result': match_result,
                'lost_item': {
                    'id': lost_item['id'],
                    'title': lost_item['title'],
                    'description': lost_item['description']
                },
                'found_item': {
                    'id': found_item['id'],
                    'title': found_item['title'],
                    'description': found_item['description']
                }
            })

        # æ¨¡å¼2: åªæä¾›æ‹›é¢†ç‰©å“ï¼Œæœç´¢æ‰€æœ‰ä¸¢å¤±ç‰©å“
        elif found_item_id and not lost_item_id:
            print("   æ¨¡å¼: æœç´¢åŒ¹é…çš„ä¸¢å¤±ç‰©å“")

            # æŸ¥æ‰¾æ‹›é¢†ç‰©å“
            found_item = None
            for item in found_items:
                if item['id'] == found_item_id:
                    found_item = item
                    break

            if not found_item:
                return jsonify({'error': 'æ‹›é¢†ç‰©å“ä¸å­˜åœ¨'}), 404

            # ä¸æ‰€æœ‰ä¸¢å¤±ç‰©å“è¿›è¡ŒåŒ¹é…
            all_matches = []
            for lost_item in lost_items:
                try:
                    match_result = ai_matcher.match_items(lost_item, found_item)

                    # åªä¿ç•™åˆ†æ•°è¾ƒé«˜çš„åŒ¹é…
                    if match_result['match_score'] > 20:
                        all_matches.append({
                            'lost_item': {
                                'id': lost_item['id'],
                                'title': lost_item['title'],
                                'description': lost_item['description']
                            },
                            'match_result': match_result
                        })

                except Exception as e:
                    print(f"åŒ¹é…å¤±è´¥: {lost_item['id']} - {e}")

            # æŒ‰åˆ†æ•°æ’åº
            all_matches.sort(key=lambda x: x['match_result']['match_score'], reverse=True)

            return jsonify({
                'success': True,
                'found_item': {
                    'id': found_item['id'],
                    'title': found_item['title'],
                    'description': found_item['description']
                },
                'matches': all_matches[:10],
                'total_matches': len(all_matches)
            })

        # æ¨¡å¼3: åªæä¾›ä¸¢å¤±ç‰©å“ï¼Œæœç´¢æ‰€æœ‰æ‹›é¢†ç‰©å“
        elif lost_item_id and not found_item_id:
            print("   æ¨¡å¼: æœç´¢åŒ¹é…çš„æ‹›é¢†ç‰©å“")

            # æŸ¥æ‰¾ä¸¢å¤±ç‰©å“
            lost_item = None
            for item in lost_items:
                if item['id'] == lost_item_id:
                    lost_item = item
                    break

            if not lost_item:
                return jsonify({'error': 'ä¸¢å¤±ç‰©å“ä¸å­˜åœ¨'}), 404

            # ä¸æ‰€æœ‰æ‹›é¢†ç‰©å“è¿›è¡ŒåŒ¹é…
            all_matches = []
            for found_item in found_items:
                try:
                    match_result = ai_matcher.match_items(lost_item, found_item)

                    # åªä¿ç•™åˆ†æ•°è¾ƒé«˜çš„åŒ¹é…
                    if match_result['match_score'] > 20:
                        all_matches.append({
                            'found_item': {
                                'id': found_item['id'],
                                'title': found_item['title'],
                                'description': found_item['description']
                            },
                            'match_result': match_result
                        })

                except Exception as e:
                    print(f"åŒ¹é…å¤±è´¥: {found_item['id']} - {e}")

            # æŒ‰åˆ†æ•°æ’åº
            all_matches.sort(key=lambda x: x['match_result']['match_score'], reverse=True)

            return jsonify({
                'success': True,
                'lost_item': {
                    'id': lost_item['id'],
                    'title': lost_item['title'],
                    'description': lost_item['description']
                },
                'matches': all_matches[:10],
                'total_matches': len(all_matches)
            })

        else:
            return jsonify({'error': 'éœ€è¦æä¾›è‡³å°‘ä¸€ä¸ªç‰©å“ID'}), 400

    except Exception as e:
        print(f"âŒ å…¼å®¹åŒ¹é…APIé”™è¯¯: {e}")
        return jsonify({'error': f'åŒ¹é…å¤±è´¥: {str(e)}'}), 500

@app.route('/api/upload', methods=['POST'])
def upload_file():
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'}), 400
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
        if not allowed_file(file.filename):
            return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}), 400
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        return jsonify({'success': True, 'filename': filename, 'url': f'/uploads/{filename}'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/uploads/<filename>')
def uploaded_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)


@app.route('/api/stats', methods=['GET'])
def get_stats():
    stats = {
        'total_lost': len(lost_items),
        'total_found': len(found_items),
        'total_matches': len(matches),
        'bert_model_loaded': ai_matcher.bert_matcher.model_loaded,
        'server_time': datetime.datetime.now().isoformat()
    }
    return jsonify(stats)


@app.route('/api/ai/describe', methods=['POST'])
def ai_describe_item():
    try:
        data = request.json
        item_type = data.get('item_type', '').strip()
        features = data.get('features', '').strip()
        if not item_type:
            return jsonify({'error': 'è¯·è¾“å…¥ç‰©å“ç±»å‹'}), 400
        description = qianwen.generate_item_description(item_type, features)
        return jsonify({'description': description})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/ai/chat', methods=['POST'])
def ai_chat():
    try:
        data = request.json
        user_message = data.get('message', '').strip()
        history = data.get('history', [])
        if not user_message:
            return jsonify({'error': 'è¯·è¾“å…¥æ¶ˆæ¯'}), 400
        ai_reply = qianwen.chat(user_message, history)
        return jsonify({'reply': ai_reply, 'timestamp': datetime.datetime.now().isoformat()})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/ai/notice', methods=['POST'])
def ai_generate_notice():
    try:
        data = request.json
        item_info = data.get('item_info', {})
        notice_type = data.get('notice_type', 'lost')
        if not item_info:
            return jsonify({'error': 'è¯·æä¾›ç‰©å“ä¿¡æ¯'}), 400
        notice = qianwen.generate_notice(item_info, notice_type)
        return jsonify({'notice': notice, 'notice_type': notice_type})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'è·¯ç”±ä¸å­˜åœ¨'}), 404


@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500


if __name__ == '__main__':
    print(f"æœåŠ¡å·²å¯åŠ¨: http://localhost:5000")
    app.run(debug=True, host='0.0.0.0', port=5000)